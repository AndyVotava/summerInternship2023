{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c594495e-ae4d-4377-a851-200e3607357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 16:39:34.069842: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-10 16:39:34.179125: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-10 16:39:39.079426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8f2268-ecfc-422a-873d-3cdceb248f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584cb593-0363-431d-bc41-146c6c41c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2529 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#DEFINE AND AUGMENT TRAIN DATA\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    './Datasheet_RPS/train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    batch_size=32,\n",
    "    image_size=(30, 30),\n",
    "    shuffle=True,\n",
    "    seed=10,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c4b965-5e3c-4fc1-a6ab-3aaf11509288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#DEFINE AND AUGMENT VALIDATION DATA\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    './Datasheet_RPS/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    batch_size=32,\n",
    "    image_size=(30, 30),\n",
    "    shuffle=True,\n",
    "    seed=10,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92659d8-85ce-4705-9d72-8873762310c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 16:39:48.018599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [2529]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-07-10 16:39:48.019228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2529]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#NORMALIZATION\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbaa5e-e8e7-4f3e-ad93-7eee827954f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CREATE MODEL\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(90, 3, activation='relu', input_shape=(30,30,3)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69240ab-0667-4e94-b4ee-f31001c90d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning, PruningSummaries\n",
    "\n",
    "pruning_params = {\n",
    "\n",
    "    \"pruning_schedule\": pruning_schedule.PolynomialDecay(\n",
    "    initial_sparsity = 0,\n",
    "    final_sparsity = .9,\n",
    "    begin_step = 500,\n",
    "    end_step = 2000,\n",
    "    power=2,\n",
    "    frequency=100)\n",
    "    \n",
    "\n",
    "    }\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f85e1-06bc-4980-ae49-b230dd21a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83726488-f066-401f-b97c-31a2ec737738",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam()\n",
    "optimizer.learning_rate.assign(0.00001)\n",
    "\n",
    "call = []\n",
    "call.append(pruning_callbacks.UpdatePruningStep())\n",
    "call.append(tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.1,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=18,\n",
    "))\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867aece-bc18-42c8-8843-55a151d66b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs,\n",
    "  callbacks=call\n",
    ")\n",
    "model = strip_pruning(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7341a0-3793-468e-92fb-c6e7188481a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.layers[0].weights[0].numpy()\n",
    "h, b = np.histogram(w, bins=100)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.bar(b[:-1], h, width=b[1] - b[0])\n",
    "plt.semilogy()\n",
    "print('% of zeros = {}'.format(np.sum(w == 0) / np.size(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a00ab-77bc-4a16-8656-f9c471416d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=epochs\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c36ed7-ea7d-4e4a-9b2f-38bf3192b8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tiny]",
   "language": "python",
   "name": "conda-env-.conda-tiny-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
